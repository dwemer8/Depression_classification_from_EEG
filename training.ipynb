{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde1c89e-a7fb-412b-ae7b-58f9e4232d45",
   "metadata": {},
   "source": [
    "# Libraries installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f16a32f-5c26-4217-b41b-46495e5c0aaa",
   "metadata": {
    "editable": true,
    "id": "qADYGk7ZpvHb",
    "outputId": "b376d164-1a61-4cc3-f008-17f63ae82bcd",
    "papermill": {
     "duration": 0.242633,
     "end_time": "2023-12-09T21:36:16.886705",
     "exception": false,
     "start_time": "2023-12-09T21:36:16.644072",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip uninstall torch torchvision torchaudio -y\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
    "# !pip install mne -q\n",
    "# !pip install wandb -q\n",
    "# !pip install tensorboard -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ddf29-61ce-4110-adbc-85bbcc5bb5a0",
   "metadata": {
    "id": "u9hcW97IpFLP",
    "papermill": {
     "duration": 0.23434,
     "end_time": "2023-12-09T21:36:17.845916",
     "exception": false,
     "start_time": "2023-12-09T21:36:17.611576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Constants and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc489da4-94c3-47da-9f16-dfc99da8681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n",
      "\n",
      "PROJECT_FOLDER = ''\n",
      "SRC_FOLDER = ''\n",
      "OUTPUT_FOLDER = ''\n",
      "\n",
      "TUAB_DIRECTORY = 'Data/TUAB/'\n",
      "TUAB_TRAIN = 'Data/TUAB/train/normal/01_tcp_ar/'\n",
      "TUAB_EVAL = 'Data/TUAB/eval/normal/01_tcp_ar/'\n",
      "\n",
      "DEPR_ANON_DIRECTORY = 'Data/depression_anonymized/'\n",
      "\n",
      "INHOUSE_DIRECTORY = 'Data/inhouse_dataset/EEG_baseline_with_markers_cleaned/preprocessed_data/EEG_baseline/'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "In this section one defines environment variables. \n",
    "Because I used this notebook on number of machines, I implemented class especially for this. \n",
    "You may not needed in one and use just simple definitions.\n",
    "'''\n",
    "\n",
    "from system_variables import SystemVariables\n",
    "\n",
    "# choose system according your current machine\n",
    "# SYSTEM_NAME = \"Windows\"\n",
    "# SYSTEM_NAME = \"Colab\"\n",
    "# SYSTEM_NAME = \"Kaggle\"\n",
    "SYSTEM_NAME = \"Linux\"\n",
    "\n",
    "sv = SystemVariables(SYSTEM_NAME)\n",
    "PROJECT_FOLDER = sv.get_project_folder()\n",
    "SRC_FOLDER = sv.get_src_folder()\n",
    "OUTPUT_FOLDER = sv.get_output_folder()\n",
    "TUAB_DIRECTORY, TUAB_TRAIN, TUAB_EVAL = sv.get_TUAB_folders()\n",
    "DEPR_ANON_DIRECTORY = sv.get_depr_anon_folder()\n",
    "INHOUSE_DIRECTORY = sv.get_inhouse_folder()\n",
    "\n",
    "print(SYSTEM_NAME)\n",
    "print()\n",
    "\n",
    "print(f\"{PROJECT_FOLDER = }\")\n",
    "print(f\"{SRC_FOLDER = }\")\n",
    "print(f\"{OUTPUT_FOLDER = }\")\n",
    "print()\n",
    "\n",
    "print(f\"{TUAB_DIRECTORY = }\")\n",
    "print(f\"{TUAB_TRAIN = }\")\n",
    "print(f\"{TUAB_EVAL = }\")\n",
    "print()\n",
    "\n",
    "print(f\"{DEPR_ANON_DIRECTORY = }\")\n",
    "print()\n",
    "\n",
    "print(f\"{INHOUSE_DIRECTORY = }\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f042a9-5514-49bf-bff7-83a945b55f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "from IPython.display import display, clear_output\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, roc_auc_score\n",
    "\n",
    "from tqdm.auto import tqdm as tqdm_auto\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard\n",
    "\n",
    "import wandb\n",
    "!wandb login 1b8e8dc9dcf1a34397a04197c4826d3fe7441dae\n",
    "\n",
    "import mne\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e037a53a-6b68-47e0-9626-fc39f738a70c",
   "metadata": {
    "id": "xhokb8oipFLR",
    "outputId": "b86fecdb-1101-40ee-df27-23de85372207",
    "papermill": {
     "duration": 22.337897,
     "end_time": "2023-12-09T21:36:40.911773",
     "exception": false,
     "start_time": "2023-12-09T21:36:18.573876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(SRC_FOLDER)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport utils\n",
    "\n",
    "from utils import SEED\n",
    "from utils.common import objectName, seed_all, printLog, upd, Config\n",
    "from utils.models_evaluation import evaluateClassifier, evaluateRegressor, evaluateClassifier_inner_outer_cv\n",
    "from utils.data_reading import DataReader\n",
    "from utils.plotting import dataset_hists, plotData, dict_to_df, printDatasetMeta, printDataloaderMeta, plotSamplesFromDataset\n",
    "from utils.dataset import InMemoryDataset\n",
    "from utils.logger import Logger\n",
    "from utils.parser import parse_ml_config\n",
    "\n",
    "from models import get_model, load_weights_from_wandb\n",
    "from models.modules import encoder_conv, decoder_conv, encoder_conv4, decoder_conv4\n",
    "from models.VAE import VAE, BetaVAE_H, BetaVAE_B\n",
    "from models.AE import AE, AE_framework\n",
    "from models.UNet import UNet\n",
    "\n",
    "from training import train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a880451f-35ee-4bfc-ad48-225b55c5b0b7",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c756beee-8cef-4905-ba5d-d1ca44f9eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {\n",
    "    \"loss_coefs\": {\n",
    "        \"ampl\": 1,\n",
    "        \"vel\": 0,\n",
    "        \"acc\": 0,\n",
    "        \"frq\": 0,\n",
    "        \"kl\": 1\n",
    "    },\n",
    "    \"masking\" :{\n",
    "        \"n_masks\" : 0, #0/1\n",
    "        \"mask_ratio\" : 0 #[0, 1]\n",
    "    },\n",
    "    \n",
    "    \"start_epoch\": 0, # including\n",
    "    \"end_epoch\": 50, # excluding,\n",
    "    \"step_max\" : None,\n",
    "\n",
    "    \"validation\": {\n",
    "        \"check_period\": 1e10,\n",
    "        \"plot_period\": None, #1e10\n",
    "    }\n",
    "}\n",
    "\n",
    "logger_config = {\n",
    "    \"log_type\" : \"wandb\", #\"wandb\"/\"tensorboard\"/\"none\"\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"model\": \"AE\",\n",
    "    \"loss_reduction\" : \"mean\",\n",
    "    \"model_description\": \"depr. anon., AE, 3 ch., 4/8/16/32, 7/7/5/3/3/3/3/1, Sigmoid\",\n",
    "    # \"artifact\" : 'dmitriykornilov_team/EEG_age_prediction/AE:v18',\n",
    "    # \"file\": '50_epoch.pth'\n",
    "}\n",
    "\n",
    "dataset_config = {\n",
    "    \"batch_size\": 256,\n",
    "    \"num_workers\": 0,\n",
    "    \"dataset\": \"depression_anonymized\", #inhouse_dataset/depression_anonymized/TUAB\n",
    "    \"dataset_file\": DEPR_ANON_DIRECTORY + \"dataset_128_10.0.pkl\", #DEPR_ANON_DIRECTORY + \"dataset_128_10.0.pkl\" / INHOUSE_DIRECTORY + \"dataset.pkl\" / TUAB_DIRECTORY + \"dataset_fz_cz_pz_3x124.pkl\"\n",
    "    \"val_size\" : 30, #n_val_patients\n",
    "    \"test_size\" : 30, #n_test_patients\n",
    "}\n",
    "\n",
    "optimizer_config = {\n",
    "    \"optimizer\" : \"AdamW\",\n",
    "    \"kwargs\": {\n",
    "        \"lr\": 1e-3\n",
    "    }\n",
    "}\n",
    "\n",
    "scheduler_config = {\n",
    "    \"scheduler\" : \"ReduceLROnPlateau\",\n",
    "    \"kwargs\": {\n",
    "        \"factor\": 0.5,\n",
    "        \"patience\": 3, \n",
    "        \"verbose\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "ml_config = {\n",
    "    \"avg_embeddings_over_time\": True,\n",
    "    \"plot_type\": \"classification\", #\"regression\"/\"classification\"\n",
    "    \"ml_model\": {\n",
    "        \"scaler\" : \"preprocessing.StandardScaler\",\n",
    "        \"clf\": \"svm.SVC\",\n",
    "    },\n",
    "    \"ml_param_grid\" : {\n",
    "        'clf__kernel': ['linear'],\n",
    "        'clf__C': list(np.logspace(-1, 1, 3)),\n",
    "        'clf__probability': [True],\n",
    "        'clf__class_weight': ['balanced'],\n",
    "        'clf__random_state': [SEED]\n",
    "    },\n",
    "    \"ml_eval_function\" : [\n",
    "        \"evaluateClassifier_inner_outer_cv\",\n",
    "        \"evaluateClassifier\", \n",
    "    ],\n",
    "    \"ml_eval_function_tag\" : [\"cv\", \"d\"],\n",
    "    \"ml_eval_function_kwargs\" : [\n",
    "        {\n",
    "            \"verbose\" : 2,\n",
    "            \"SEED\" : SEED,\n",
    "            \"cv_scorer\" : \"accuracy_score\",\n",
    "            \"metrics\" : [(\"average_precision_score\", \"soft\"), (\"roc_auc_score\", \"soft\"), (\"accuracy_score\", \"hard\"), (\"f1_score\", \"hard\")],\n",
    "            \"n_splits_inner\" : 5,\n",
    "            \"n_splits_outer\" : 10,\n",
    "        },\n",
    "        {\n",
    "            \"verbose\" : 1,\n",
    "            \"test_size\" : 0.33,\n",
    "            \"SEED\" : SEED,\n",
    "            \"cv_scorer\" : \"accuracy_score\",\n",
    "            \"metrics\" : [(\"average_precision_score\", \"soft\"), (\"roc_auc_score\", \"soft\"), (\"accuracy_score\", \"hard\"), (\"f1_score\", \"hard\")],\n",
    "            # \"metrics_for_CI\" : [(\"average_precision_score\", \"soft\"), (\"roc_auc_score\", \"soft\"), (\"accuracy_score\", \"hard\"), (\"f1_score\", \"hard\")],\n",
    "            # \"n_bootstraps\" : 1000\n",
    "        },\n",
    "    ],\n",
    "    \"ml_metric_prefix\" : \"clf\",\n",
    "    \n",
    "    # ml_model=Pipeline([('scaler', StandardScaler()), ('reg', Ridge())]),\n",
    "    # ml_param_grid={\n",
    "    #     'reg__alpha': np.logspace(-2, 2, 5),\n",
    "    #     # 'reg__solver': ['sag'],\n",
    "    #     # 'reg__tol': [1e-4]\n",
    "    # },\n",
    "    # ml_eval_function=evaluateRegressor,\n",
    "    # ml_metric_names=[\"mse_test\", \"mse_train\"],\n",
    "    # ml_metric_prefix=\"reg\",\n",
    "}\n",
    "\n",
    "\n",
    "default_config = {\n",
    "    \"project_name\": 'EEG_depression_classification',\n",
    "    \"method\": \"direct restoration\",\n",
    "    \"save_path\" : OUTPUT_FOLDER + 'model_weights/',\n",
    "    \"log_path\" : OUTPUT_FOLDER + \"logs/\",\n",
    "    \n",
    "    \"dataset\": dataset_config,\n",
    "    \"model\": model_config,\n",
    "    \"optimizer\" : optimizer_config,\n",
    "    \"scheduler\": scheduler_config,\n",
    "    \"train\": train_config,\n",
    "    \"ml\": ml_config,\n",
    "    \"logger\": logger_config,\n",
    "}\n",
    "\n",
    "# print(\"Config:\", json.dumps(default_config, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774678f7-4d4e-4eea-b999-e08931e15d47",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b621b73e-25da-40e8-b82d-06e26ed8b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = Config(default_config)\n",
    "\n",
    "experiments = [\n",
    "    dc.upd({\n",
    "        \"dataset\" : {\"dataset_file\": DEPR_ANON_DIRECTORY + f\"dataset_128_{x}.0.pkl\"},\n",
    "        \"model\": {\"model_description\": f\"depr. anon., AE, 3 ch., 4/8/16/32, 7/7/5/3/3/3/3/1, Sigmoid, {x} s\"},\n",
    "    })\n",
    "    for x in [1, 2, 4, 5, 10, 15, 30, 60]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7668e523-030a-4a72-ab67-9b9b117be419",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a94814b-e6ca-4c80-9dd6-8bd83ff03102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, verbose=0):\n",
    "    try:\n",
    "        if config[\"log_path\"] is not None: logfile = open(os.path.join(config[\"log_path\"], config[\"model\"][\"model_description\"].replace(\" \", \"_\").replace(\"/\", \".\")), \"a\")\n",
    "        else: logfile = None\n",
    "        printLog('#################### ' + config[\"model\"][\"model_description\"] + ' ####################', logfile=logfile)\n",
    "        printLog(json.dumps(config, indent=4), logfile=logfile)\n",
    "        \n",
    "        #Data reading\n",
    "        if verbose - 1 > 0: printLog(\"Data reading\", logfile=logfile)\n",
    "        reader = DataReader(\n",
    "            config[\"dataset\"][\"dataset_file\"], \n",
    "            dataset_type=config[\"dataset\"][\"dataset\"],\n",
    "            verbose=(verbose-1)\n",
    "        )\n",
    "        train_set, val_set, test_set = reader.split(val_size=config[\"dataset\"][\"val_size\"], test_size=config[\"dataset\"][\"test_size\"])    \n",
    "        chunks_train, chunks_val, chunks_test = train_set[\"chunk\"], val_set[\"chunk\"], test_set[\"chunk\"]\n",
    "        targets_train, targets_val, targets_test = train_set[\"target\"], val_set[\"target\"], test_set[\"target\"]\n",
    "        \n",
    "        config[\"dataset\"].update({\n",
    "            \"samples_shape\": chunks_train[0].shape,\n",
    "            \"n_train_samples\": len(chunks_train),\n",
    "            \"n_validation_samples\": len(chunks_val),\n",
    "            \"n_test_samples\": len(chunks_test),\n",
    "        })\n",
    "    \n",
    "        t_max=None\n",
    "        train_dataset = InMemoryDataset(chunks_train, is_squeeze=False, is_unsqueeze=False, t_max=t_max)\n",
    "        val_dataset = InMemoryDataset(chunks_val, is_squeeze=False, is_unsqueeze=False, t_max=t_max)\n",
    "        test_dataset = InMemoryDataset(chunks_test, is_squeeze=False, is_unsqueeze=False, t_max=t_max)\n",
    "    \n",
    "        if verbose - 2 > 0: \n",
    "            printDatasetMeta(train_dataset, val_dataset, test_dataset)\n",
    "            plotSamplesFromDataset(train_dataset)\n",
    "    \n",
    "        #Dataloader\n",
    "        train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=config[\"dataset\"]['batch_size'], num_workers=config[\"dataset\"]['num_workers'])\n",
    "        val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=config[\"dataset\"]['batch_size'], num_workers=config[\"dataset\"]['num_workers'])\n",
    "        test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=config[\"dataset\"]['batch_size'], num_workers=config[\"dataset\"]['num_workers'])\n",
    "    \n",
    "        if verbose - 2 > 0: printDataloaderMeta(train_dataloader, val_dataloader, test_dataloader)\n",
    "    \n",
    "        #Model\n",
    "        config[\"model\"].update({\n",
    "            \"input_dim\" : train_dataset[0].shape,\n",
    "        })\n",
    "        model, config[\"model\"] = get_model(config[\"model\"])\n",
    "        model = model.to(device)\n",
    "        if verbose - 1 > 0: printLog('model ' + config[\"model\"]['model_description'] + ' is created', logfile=logfile)\n",
    "    \n",
    "        #Download weights\n",
    "        if \"artifact\" in config[\"model\"] and \"file\" in config[\"model\"]:\n",
    "            model = load_weights_from_wandb(model, config[\"model\"][\"artifact\"], config[\"model\"][\"file\"], verbose=verbose)\n",
    "    \n",
    "        # TESTS\n",
    "        model.eval()\n",
    "        test_data_point = train_dataset[0][None].to(device)\n",
    "        inference_result = model(test_data_point)\n",
    "        reconstruct_result = model.reconstruct(test_data_point)\n",
    "        encode_result = model.encode(test_data_point)\n",
    "        if verbose - 1 > 0: \n",
    "            printLog(f\"Test data point shape: {test_data_point.shape}\", logfile=logfile)\n",
    "            printLog(f\"Test inference: {len(inference_result)}\", logfile=logfile)\n",
    "            printLog(f\"Test reconstruct: {reconstruct_result.shape}\", logfile=logfile)\n",
    "            printLog(f\"Test encode: {encode_result.shape}\", logfile=logfile)\n",
    "    \n",
    "        #optimizer and scheduler\n",
    "        optimizer = getattr(torch.optim, config[\"optimizer\"][\"optimizer\"])(model.parameters(), **config[\"optimizer\"][\"kwargs\"])\n",
    "        if verbose - 1 > 0: printLog(f'Optimizer {type(optimizer).__name__} is instantiated', logfile=logfile)\n",
    "    \n",
    "        scheduler = getattr(torch.optim.lr_scheduler, config[\"scheduler\"][\"scheduler\"])(optimizer, **config[\"scheduler\"][\"kwargs\"])\n",
    "        if verbose - 1 > 0: printLog(f'Scheduler {type(scheduler).__name__} is instantiated', logfile=logfile)\n",
    "    \n",
    "        logger = Logger(\n",
    "            log_type=config[\"logger\"][\"log_type\"], \n",
    "            run_name=config[\"model\"][\"model_description\"],\n",
    "            save_path=config[\"save_path\"],\n",
    "            model=model,\n",
    "            model_name=config[\"model\"][\"model\"],        \n",
    "            project_name=config[\"project_name\"],\n",
    "            config=config,\n",
    "            model_description=config[\"model\"][\"model_description\"],\n",
    "        #         log_dir = OUTPUT_FOLDER + \"logs/\"\n",
    "        )\n",
    "    \n",
    "        #parse ml config\n",
    "        #should be just before training because replace names by objects\n",
    "        config[\"ml\"] = parse_ml_config(config[\"ml\"])\n",
    "    \n",
    "        #seed\n",
    "        seed_all(SEED)\n",
    "    \n",
    "        #training\n",
    "        # best_loss = np.inf\n",
    "        best_clf_accuracy = -np.inf\n",
    "        best_model = None\n",
    "        best_epoch = None\n",
    "        final_model = None\n",
    "        \n",
    "        for epoch in tqdm_auto(range(config[\"train\"]['start_epoch'], config[\"train\"]['end_epoch'])):\n",
    "            if verbose > 0: printLog(f\"Epoch {epoch}\", logfile=logfile)\n",
    "            \n",
    "            #######\n",
    "            # train\n",
    "            #######\n",
    "            if verbose > 0: printLog(\"##### Training... #####\", logfile=logfile)\n",
    "            model, results = train_eval(\n",
    "                train_dataloader,\n",
    "                model,\n",
    "                device=device,\n",
    "                mode=\"train\",\n",
    "                optimizer=optimizer,\n",
    "                epoch=epoch,\n",
    "                logger=logger,\n",
    "                loss_coefs=config[\"train\"][\"loss_coefs\"],\n",
    "                loss_reduction=config[\"model\"][\"loss_reduction\"],\n",
    "                is_mask=(config[\"train\"][\"masking\"][\"n_masks\"] != 0 and config[\"train\"][\"masking\"][\"mask_ratio\"] != 0),\n",
    "                mask_ratio=config[\"train\"][\"masking\"][\"mask_ratio\"],\n",
    "                step_max=config[\"train\"][\"step_max\"], \n",
    "            )\n",
    "            if results == {}: break\n",
    "            if verbose > 0: \n",
    "                display(dict_to_df(results))\n",
    "                for k in results: \n",
    "                    if isinstance(results[k], np.ndarray): results[k] = float(results[k].tolist())\n",
    "                print(json.dumps(results, indent=4), file=logfile)\n",
    "    \n",
    "            ############\n",
    "            # validation\n",
    "            ############\n",
    "            if verbose > 0: printLog(\"##### Validation... #####\", logfile=logfile)\n",
    "            model, results = train_eval(\n",
    "                val_dataloader,\n",
    "                model,\n",
    "                device=device,\n",
    "                mode=\"validation\",\n",
    "                test_dataset=val_dataset,\n",
    "                targets_test=targets_val,\n",
    "                check_period=config[\"train\"][\"validation\"][\"check_period\"],\n",
    "                plot_period=config[\"train\"][\"validation\"][\"plot_period\"],\n",
    "                epoch=epoch,\n",
    "                logger=logger,\n",
    "                loss_coefs=config[\"train\"][\"loss_coefs\"],\n",
    "                loss_reduction=config[\"model\"][\"loss_reduction\"],\n",
    "                is_mask=(config[\"train\"][\"masking\"][\"n_masks\"] != 0 and config[\"train\"][\"masking\"][\"mask_ratio\"] != 0),\n",
    "                mask_ratio=config[\"train\"][\"masking\"][\"mask_ratio\"],\n",
    "                step_max=config[\"train\"][\"step_max\"], \n",
    "                **config[\"ml\"],\n",
    "            )\n",
    "            if results == {}: break\n",
    "            if verbose > 0: \n",
    "                display(dict_to_df(results))\n",
    "                for k in results: \n",
    "                    if type(results[k]) == np.ndarray: results[k] = float(results[k].tolist())\n",
    "                print(json.dumps(results, indent=4), file=logfile)\n",
    "    \n",
    "            scheduler.step(results['loss'])\n",
    "            logger.save_model(epoch)\n",
    "            final_model = model\n",
    "    \n",
    "            zero_ml_tag = config[\"ml\"][\"ml_eval_function_tag\"][0]\n",
    "            if results[f'clf.{zero_ml_tag}.test.accuracy.cv'] >= best_clf_accuracy:\n",
    "                best_clf_accuracy = results[f'clf.{zero_ml_tag}.test.accuracy.cv']\n",
    "                best_model = model\n",
    "                best_epoch = best_epoch\n",
    "                if verbose > 0: printLog(f\"New best classifier accuracy = {best_clf_accuracy} on epoch {epoch}\", logfile=logfile)\n",
    "            \n",
    "            # if results['loss'] < best_loss:\n",
    "            #     best_loss = results['loss']\n",
    "            #     best_model = model\n",
    "            #     best_epoch = best_epoch\n",
    "            #     if verbose > 0: printLog(f\"New best loss = {best_loss} on epoch {epoch}\", logfile=logfile)\n",
    "    \n",
    "        logger.save_model(config[\"train\"]['end_epoch'])\n",
    "    \n",
    "        ######\n",
    "        # test\n",
    "        ######\n",
    "        results_all = {}\n",
    "        for model, mode in zip([final_model, best_model], [\"final\", \"test\"]):\n",
    "            if verbose > 0: printLog(f\"##### Testing in {mode} mode... #####\", logfile=logfile)\n",
    "            _, results = train_eval(\n",
    "                test_dataloader,\n",
    "                model,\n",
    "                device=device,\n",
    "                mode=mode,\n",
    "                test_dataset=test_dataset,\n",
    "                targets_test=targets_test,\n",
    "                check_period=1e10,\n",
    "                plot_period=1e10,\n",
    "                epoch=config[\"train\"]['end_epoch'],\n",
    "                logger=logger,\n",
    "                loss_coefs=config[\"train\"][\"loss_coefs\"],\n",
    "                loss_reduction=config[\"model\"][\"loss_reduction\"],\n",
    "                is_mask=(config[\"train\"][\"masking\"][\"n_masks\"] != 0 and config[\"train\"][\"masking\"][\"mask_ratio\"] != 0),\n",
    "                mask_ratio=config[\"train\"][\"masking\"][\"mask_ratio\"],\n",
    "                step_max=config[\"train\"][\"step_max\"], \n",
    "                **config[\"ml\"],\n",
    "            )\n",
    "            results_all[mode] = results\n",
    "            if verbose > 0: \n",
    "                display(dict_to_df(results))\n",
    "                for k in results: \n",
    "                    if type(results[k]) == np.ndarray: results[k] = float(results[k].tolist())\n",
    "                print(json.dumps(results, indent=4), file=logfile)\n",
    "        \n",
    "        logger.update_summary(\"validation.best_epoch\", best_epoch)\n",
    "        logger.finish()\n",
    "\n",
    "        logfile.close()\n",
    "        return results_all\n",
    "        \n",
    "    except Exception as error:\n",
    "        # handle the exception\n",
    "        exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "        traceback.print_exception(exc_type, exc_value, exc_traceback) \n",
    "        if logfile is not None: \n",
    "            traceback.print_exception(exc_type, exc_value, exc_traceback, file=logfile) \n",
    "            logfile.close()\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b48e9c-2996-44ba-9cbc-9802fbd69b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### depr. anon., AE, 3 ch., 4/8/16/32, 7/7/5/3/3/3/3/1, Sigmoid, 1 s ####################\n",
      "{\n",
      "    \"project_name\": \"EEG_depression_classification\",\n",
      "    \"method\": \"direct restoration\",\n",
      "    \"save_path\": \"model_weights/\",\n",
      "    \"log_path\": \"logs/\",\n",
      "    \"dataset\": {\n",
      "        \"batch_size\": 256,\n",
      "        \"num_workers\": 0,\n",
      "        \"dataset\": \"depression_anonymized\",\n",
      "        \"dataset_file\": \"Data/depression_anonymized/dataset_128_1.0.pkl\",\n",
      "        \"val_size\": 30,\n",
      "        \"test_size\": 30\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"model\": \"AE\",\n",
      "        \"loss_reduction\": \"mean\",\n",
      "        \"model_description\": \"depr. anon., AE, 3 ch., 4/8/16/32, 7/7/5/3/3/3/3/1, Sigmoid, 1 s\"\n",
      "    },\n",
      "    \"optimizer\": {\n",
      "        \"optimizer\": \"AdamW\",\n",
      "        \"kwargs\": {\n",
      "            \"lr\": 0.001\n",
      "        }\n",
      "    },\n",
      "    \"scheduler\": {\n",
      "        \"scheduler\": \"ReduceLROnPlateau\",\n",
      "        \"kwargs\": {\n",
      "            \"factor\": 0.5,\n",
      "            \"patience\": 3,\n",
      "            \"verbose\": true\n",
      "        }\n",
      "    },\n",
      "    \"train\": {\n",
      "        \"loss_coefs\": {\n",
      "            \"ampl\": 1,\n",
      "            \"vel\": 0,\n",
      "            \"acc\": 0,\n",
      "            \"frq\": 0,\n",
      "            \"kl\": 1\n",
      "        },\n",
      "        \"masking\": {\n",
      "            \"n_masks\": 0,\n",
      "            \"mask_ratio\": 0\n",
      "        },\n",
      "        \"start_epoch\": 0,\n",
      "        \"end_epoch\": 50,\n",
      "        \"step_max\": null,\n",
      "        \"validation\": {\n",
      "            \"check_period\": 10000000000.0,\n",
      "            \"plot_period\": null\n",
      "        }\n",
      "    },\n",
      "    \"ml\": {\n",
      "        \"avg_embeddings_over_time\": true,\n",
      "        \"plot_type\": \"classification\",\n",
      "        \"ml_model\": {\n",
      "            \"scaler\": \"preprocessing.StandardScaler\",\n",
      "            \"clf\": \"svm.SVC\"\n",
      "        },\n",
      "        \"ml_param_grid\": {\n",
      "            \"clf__kernel\": [\n",
      "                \"linear\"\n",
      "            ],\n",
      "            \"clf__C\": [\n",
      "                0.1,\n",
      "                1.0,\n",
      "                10.0\n",
      "            ],\n",
      "            \"clf__probability\": [\n",
      "                true\n",
      "            ],\n",
      "            \"clf__class_weight\": [\n",
      "                \"balanced\"\n",
      "            ],\n",
      "            \"clf__random_state\": [\n",
      "                42\n",
      "            ]\n",
      "        },\n",
      "        \"ml_eval_function\": [\n",
      "            \"evaluateClassifier_inner_outer_cv\",\n",
      "            \"evaluateClassifier\"\n",
      "        ],\n",
      "        \"ml_eval_function_tag\": [\n",
      "            \"cv\",\n",
      "            \"d\"\n",
      "        ],\n",
      "        \"ml_eval_function_kwargs\": [\n",
      "            {\n",
      "                \"verbose\": 2,\n",
      "                \"SEED\": 42,\n",
      "                \"cv_scorer\": \"accuracy_score\",\n",
      "                \"metrics\": [\n",
      "                    [\n",
      "                        \"average_precision_score\",\n",
      "                        \"soft\"\n",
      "                    ],\n",
      "                    [\n",
      "                        \"roc_auc_score\",\n",
      "                        \"soft\"\n",
      "                    ],\n",
      "                    [\n",
      "                        \"accuracy_score\",\n",
      "                        \"hard\"\n",
      "                    ],\n",
      "                    [\n",
      "                        \"f1_score\",\n",
      "                        \"hard\"\n",
      "                    ]\n",
      "                ],\n",
      "                \"n_splits_inner\": 5,\n",
      "                \"n_splits_outer\": 10\n",
      "            },\n",
      "            {\n",
      "                \"verbose\": 1,\n",
      "                \"test_size\": 0.33,\n",
      "                \"SEED\": 42,\n",
      "                \"cv_scorer\": \"accuracy_score\",\n",
      "                \"metrics\": [\n",
      "                    [\n",
      "                        \"average_precision_score\",\n",
      "                        \"soft\"\n",
      "                    ],\n",
      "                    [\n",
      "                        \"roc_auc_score\",\n",
      "                        \"soft\"\n",
      "                    ],\n",
      "                    [\n",
      "                        \"accuracy_score\",\n",
      "                        \"hard\"\n",
      "                    ],\n",
      "                    [\n",
      "                        \"f1_score\",\n",
      "                        \"hard\"\n",
      "                    ]\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"ml_metric_prefix\": \"clf\"\n",
      "    },\n",
      "    \"logger\": {\n",
      "        \"log_type\": \"wandb\"\n",
      "    }\n",
      "}\n",
      "Data reading\n",
      "\n",
      "Chunks shape: (3, 128) , length: 10679 , keys: dict_keys(['chunk', 'target', 'patient'])\n",
      "N patients = 178\n",
      "Train=118, validation=30, test=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10679/10679 [00:00<00:00, 32753.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7079 (3, 128)\n",
      "Validation: 1800 (3, 128)\n",
      "Test: 1800 (3, 128)\n",
      "model depr. anon., AE, 3 ch., 4/8/16/32, 7/7/5/3/3/3/3/1, Sigmoid, 1 s is created\n",
      "Test data point shape: torch.Size([1, 3, 128])\n",
      "Test inference: 1\n",
      "Test reconstruct: torch.Size([1, 3, 128])\n",
      "Test encode: torch.Size([1, 32, 16])\n",
      "Optimizer AdamW is instantiated\n",
      "Scheduler ReduceLROnPlateau is instantiated\n",
      "Logging via WandB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmitriykornilov\u001b[0m (\u001b[33mdmitriykornilov_team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/work/Autoencoders/wandb/run-20240114_121442-psd5yj1c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmitriykornilov_team/EEG_depression_classification/runs/psd5yj1c' target=\"_blank\">depr. anon., AE, 3 ch., 4/8/16/32, 7/7/5/3/3/3/3/1, Sigmoid, 1 s</a></strong> to <a href='https://wandb.ai/dmitriykornilov_team/EEG_depression_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmitriykornilov_team/EEG_depression_classification' target=\"_blank\">https://wandb.ai/dmitriykornilov_team/EEG_depression_classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmitriykornilov_team/EEG_depression_classification/runs/psd5yj1c' target=\"_blank\">https://wandb.ai/dmitriykornilov_team/EEG_depression_classification/runs/psd5yj1c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                   | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "##### Training... #####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>metric</th>\n",
       "      <th>pearson_correlation</th>\n",
       "      <th>snr_db</th>\n",
       "      <th>loss_ampl</th>\n",
       "      <th>loss_vel</th>\n",
       "      <th>loss_acc</th>\n",
       "      <th>loss_frq</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.159</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.384</td>\n",
       "      <td>3.836</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss metric pearson_correlation snr_db loss_ampl loss_vel loss_acc  \\\n",
       "0  0.159  0.841               0.384  3.836     0.159    0.008    0.008   \n",
       "\n",
       "  loss_frq   RMSE     lr  \n",
       "0    0.012  0.397  0.001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Validation... #####\n",
      "GridSearchCV\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best estimator: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('clf',\n",
      "                 SVC(class_weight='balanced', kernel='linear', probability=True,\n",
      "                     random_state=42))])\n",
      "Evaluation on the train data\n",
      "average_precision, 0.95% interval from cross-validation: 0.762+-0.061\n",
      "roc_auc, 0.95% interval from cross-validation: 0.753+-0.081\n",
      "accuracy, 0.95% interval from cross-validation: 0.683+-0.067\n",
      "f1, 0.95% interval from cross-validation: 0.656+-0.064\n",
      "Evaluation on the test data\n",
      "average_precision, 0.95% interval from cross-validation: 0.768+-0.071\n",
      "roc_auc, 0.95% interval from cross-validation: 0.756+-0.061\n",
      "accuracy, 0.95% interval from cross-validation: 0.683+-0.040\n",
      "f1, 0.95% interval from cross-validation: 0.656+-0.046\n",
      "Data split\n",
      "GridSearchCV\n",
      "Best classifier: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('clf',\n",
      "                 SVC(class_weight='balanced', kernel='linear', probability=True,\n",
      "                     random_state=42))])\n",
      "Evaluation on the train data\n",
      "Evaluation on the test data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>metric</th>\n",
       "      <th>pearson_correlation</th>\n",
       "      <th>snr_db</th>\n",
       "      <th>loss_ampl</th>\n",
       "      <th>loss_vel</th>\n",
       "      <th>loss_acc</th>\n",
       "      <th>loss_frq</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>clf.cv.train.average_precision.cv</th>\n",
       "      <th>clf.cv.train.average_precision.se.cv</th>\n",
       "      <th>clf.cv.train.roc_auc.cv</th>\n",
       "      <th>clf.cv.train.roc_auc.se.cv</th>\n",
       "      <th>clf.cv.train.accuracy.cv</th>\n",
       "      <th>clf.cv.train.accuracy.se.cv</th>\n",
       "      <th>clf.cv.train.f1.cv</th>\n",
       "      <th>clf.cv.train.f1.se.cv</th>\n",
       "      <th>clf.cv.test.average_precision.cv</th>\n",
       "      <th>clf.cv.test.average_precision.se.cv</th>\n",
       "      <th>clf.cv.test.roc_auc.cv</th>\n",
       "      <th>clf.cv.test.roc_auc.se.cv</th>\n",
       "      <th>clf.cv.test.accuracy.cv</th>\n",
       "      <th>clf.cv.test.accuracy.se.cv</th>\n",
       "      <th>clf.cv.test.f1.cv</th>\n",
       "      <th>clf.cv.test.f1.se.cv</th>\n",
       "      <th>clf.d.train.average_precision</th>\n",
       "      <th>clf.d.train.roc_auc</th>\n",
       "      <th>clf.d.train.accuracy</th>\n",
       "      <th>clf.d.train.f1</th>\n",
       "      <th>clf.d.train.sensitivity</th>\n",
       "      <th>clf.d.train.specificity</th>\n",
       "      <th>clf.d.test.average_precision</th>\n",
       "      <th>clf.d.test.roc_auc</th>\n",
       "      <th>clf.d.test.accuracy</th>\n",
       "      <th>clf.d.test.f1</th>\n",
       "      <th>clf.d.test.sensitivity</th>\n",
       "      <th>clf.d.test.specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.146</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.004</td>\n",
       "      <td>4.172</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss metric pearson_correlation snr_db loss_ampl loss_vel loss_acc  \\\n",
       "0  0.146  0.854               0.004  4.172     0.146    0.006    0.005   \n",
       "\n",
       "  loss_frq   RMSE clf.cv.train.average_precision.cv  \\\n",
       "0    0.012  0.382                             0.762   \n",
       "\n",
       "  clf.cv.train.average_precision.se.cv clf.cv.train.roc_auc.cv  \\\n",
       "0                                0.061                   0.753   \n",
       "\n",
       "  clf.cv.train.roc_auc.se.cv clf.cv.train.accuracy.cv  \\\n",
       "0                      0.081                    0.683   \n",
       "\n",
       "  clf.cv.train.accuracy.se.cv clf.cv.train.f1.cv clf.cv.train.f1.se.cv  \\\n",
       "0                       0.067              0.656                 0.064   \n",
       "\n",
       "  clf.cv.test.average_precision.cv clf.cv.test.average_precision.se.cv  \\\n",
       "0                            0.768                               0.071   \n",
       "\n",
       "  clf.cv.test.roc_auc.cv clf.cv.test.roc_auc.se.cv clf.cv.test.accuracy.cv  \\\n",
       "0                  0.756                     0.061                   0.683   \n",
       "\n",
       "  clf.cv.test.accuracy.se.cv clf.cv.test.f1.cv clf.cv.test.f1.se.cv  \\\n",
       "0                      0.040             0.656                0.046   \n",
       "\n",
       "  clf.d.train.average_precision clf.d.train.roc_auc clf.d.train.accuracy  \\\n",
       "0                         0.796               0.780                0.706   \n",
       "\n",
       "  clf.d.train.f1 clf.d.train.sensitivity clf.d.train.specificity  \\\n",
       "0          0.696                   0.657                   0.757   \n",
       "\n",
       "  clf.d.test.average_precision clf.d.test.roc_auc clf.d.test.accuracy  \\\n",
       "0                        0.735              0.743               0.675   \n",
       "\n",
       "  clf.d.test.f1 clf.d.test.sensitivity clf.d.test.specificity  \n",
       "0         0.645                  0.621                  0.724  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▍                                                                                                                      | 1/50 [01:35<1:18:04, 95.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best classifier accuracy = 0.6833333333333333 on epoch 0\n",
      "Epoch 1\n",
      "##### Training... #####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>metric</th>\n",
       "      <th>pearson_correlation</th>\n",
       "      <th>snr_db</th>\n",
       "      <th>loss_ampl</th>\n",
       "      <th>loss_vel</th>\n",
       "      <th>loss_acc</th>\n",
       "      <th>loss_frq</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.535</td>\n",
       "      <td>5.645</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss metric pearson_correlation snr_db loss_ampl loss_vel loss_acc  \\\n",
       "0  0.107  0.893               0.535  5.645     0.107    0.008    0.008   \n",
       "\n",
       "  loss_frq   RMSE     lr  \n",
       "0    0.012  0.326  0.001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Validation... #####\n",
      "GridSearchCV\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best estimator: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('clf',\n",
      "                 SVC(C=0.1, class_weight='balanced', kernel='linear',\n",
      "                     probability=True, random_state=42))])\n",
      "Evaluation on the train data\n",
      "average_precision, 0.95% interval from cross-validation: 0.747+-0.081\n",
      "roc_auc, 0.95% interval from cross-validation: 0.750+-0.055\n",
      "accuracy, 0.95% interval from cross-validation: 0.683+-0.052\n",
      "f1, 0.95% interval from cross-validation: 0.656+-0.061\n",
      "Evaluation on the test data\n",
      "average_precision, 0.95% interval from cross-validation: 0.753+-0.060\n",
      "roc_auc, 0.95% interval from cross-validation: 0.750+-0.054\n",
      "accuracy, 0.95% interval from cross-validation: 0.681+-0.079\n",
      "f1, 0.95% interval from cross-validation: 0.651+-0.093\n",
      "Data split\n",
      "GridSearchCV\n",
      "Best classifier: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('clf',\n",
      "                 SVC(C=0.1, class_weight='balanced', kernel='linear',\n",
      "                     probability=True, random_state=42))])\n",
      "Evaluation on the train data\n",
      "Evaluation on the test data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>metric</th>\n",
       "      <th>pearson_correlation</th>\n",
       "      <th>snr_db</th>\n",
       "      <th>loss_ampl</th>\n",
       "      <th>loss_vel</th>\n",
       "      <th>loss_acc</th>\n",
       "      <th>loss_frq</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>clf.cv.train.average_precision.cv</th>\n",
       "      <th>clf.cv.train.average_precision.se.cv</th>\n",
       "      <th>clf.cv.train.roc_auc.cv</th>\n",
       "      <th>clf.cv.train.roc_auc.se.cv</th>\n",
       "      <th>clf.cv.train.accuracy.cv</th>\n",
       "      <th>clf.cv.train.accuracy.se.cv</th>\n",
       "      <th>clf.cv.train.f1.cv</th>\n",
       "      <th>clf.cv.train.f1.se.cv</th>\n",
       "      <th>clf.cv.test.average_precision.cv</th>\n",
       "      <th>clf.cv.test.average_precision.se.cv</th>\n",
       "      <th>clf.cv.test.roc_auc.cv</th>\n",
       "      <th>clf.cv.test.roc_auc.se.cv</th>\n",
       "      <th>clf.cv.test.accuracy.cv</th>\n",
       "      <th>clf.cv.test.accuracy.se.cv</th>\n",
       "      <th>clf.cv.test.f1.cv</th>\n",
       "      <th>clf.cv.test.f1.se.cv</th>\n",
       "      <th>clf.d.train.average_precision</th>\n",
       "      <th>clf.d.train.roc_auc</th>\n",
       "      <th>clf.d.train.accuracy</th>\n",
       "      <th>clf.d.train.f1</th>\n",
       "      <th>clf.d.train.sensitivity</th>\n",
       "      <th>clf.d.train.specificity</th>\n",
       "      <th>clf.d.test.average_precision</th>\n",
       "      <th>clf.d.test.roc_auc</th>\n",
       "      <th>clf.d.test.accuracy</th>\n",
       "      <th>clf.d.test.f1</th>\n",
       "      <th>clf.d.test.sensitivity</th>\n",
       "      <th>clf.d.test.specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.559</td>\n",
       "      <td>6.069</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss metric pearson_correlation snr_db loss_ampl loss_vel loss_acc  \\\n",
       "0  0.090  0.910               0.559  6.069     0.090    0.006    0.006   \n",
       "\n",
       "  loss_frq   RMSE clf.cv.train.average_precision.cv  \\\n",
       "0    0.012  0.300                             0.747   \n",
       "\n",
       "  clf.cv.train.average_precision.se.cv clf.cv.train.roc_auc.cv  \\\n",
       "0                                0.081                   0.750   \n",
       "\n",
       "  clf.cv.train.roc_auc.se.cv clf.cv.train.accuracy.cv  \\\n",
       "0                      0.055                    0.683   \n",
       "\n",
       "  clf.cv.train.accuracy.se.cv clf.cv.train.f1.cv clf.cv.train.f1.se.cv  \\\n",
       "0                       0.052              0.656                 0.061   \n",
       "\n",
       "  clf.cv.test.average_precision.cv clf.cv.test.average_precision.se.cv  \\\n",
       "0                            0.753                               0.060   \n",
       "\n",
       "  clf.cv.test.roc_auc.cv clf.cv.test.roc_auc.se.cv clf.cv.test.accuracy.cv  \\\n",
       "0                  0.750                     0.054                   0.681   \n",
       "\n",
       "  clf.cv.test.accuracy.se.cv clf.cv.test.f1.cv clf.cv.test.f1.se.cv  \\\n",
       "0                      0.079             0.651                0.093   \n",
       "\n",
       "  clf.d.train.average_precision clf.d.train.roc_auc clf.d.train.accuracy  \\\n",
       "0                         0.756               0.770                0.700   \n",
       "\n",
       "  clf.d.train.f1 clf.d.train.sensitivity clf.d.train.specificity  \\\n",
       "0          0.677                   0.634                   0.765   \n",
       "\n",
       "  clf.d.test.average_precision clf.d.test.roc_auc clf.d.test.accuracy  \\\n",
       "0                        0.756              0.739               0.670   \n",
       "\n",
       "  clf.d.test.f1 clf.d.test.sensitivity clf.d.test.specificity  \n",
       "0         0.644                  0.586                  0.757  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▉                                                                                                                      | 2/50 [02:31<57:44, 72.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "##### Training... #####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>metric</th>\n",
       "      <th>pearson_correlation</th>\n",
       "      <th>snr_db</th>\n",
       "      <th>loss_ampl</th>\n",
       "      <th>loss_vel</th>\n",
       "      <th>loss_acc</th>\n",
       "      <th>loss_frq</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.583</td>\n",
       "      <td>7.058</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss metric pearson_correlation snr_db loss_ampl loss_vel loss_acc  \\\n",
       "0  0.073  0.927               0.583  7.058     0.073    0.007    0.008   \n",
       "\n",
       "  loss_frq   RMSE     lr  \n",
       "0    0.012  0.269  0.001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Validation... #####\n",
      "GridSearchCV\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best estimator: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('clf',\n",
      "                 SVC(C=10.0, class_weight='balanced', kernel='linear',\n",
      "                     probability=True, random_state=42))])\n",
      "Evaluation on the train data\n",
      "average_precision, 0.95% interval from cross-validation: 0.756+-0.050\n",
      "roc_auc, 0.95% interval from cross-validation: 0.747+-0.054\n",
      "accuracy, 0.95% interval from cross-validation: 0.678+-0.042\n",
      "f1, 0.95% interval from cross-validation: 0.654+-0.055\n",
      "Evaluation on the test data\n",
      "average_precision, 0.95% interval from cross-validation: 0.767+-0.069\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "for config in experiments:\n",
    "    all_results.append(train(config, verbose=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
